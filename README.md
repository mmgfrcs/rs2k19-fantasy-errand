# Fantasy Errand
Research on Dynamic Balancing in an Endless Running Game on an Augmented Reality platform using Face Expression and Emotion Recognition

Approved by supervisor

## Abstract
Game is a media of entertainment and can be enjoyed by many people of ages, with differing genre to enhance that experience. Games are generally enjoyed with specific rules to decide winning conditions. People seek the euphoria of getting that winning conditions as goals in playing games (Moniaga, Chowanda, Prima, Oscar, & Tri Rizqi, 2018). Players are prone to showing their emotions and expressions (Lazzaro, 2004), will laugh in a fun and silly gameplay and story, sad as some characters in the game that the player is attached to are dead or gone, get scared in a horror-inducing environment, etc.

Presently, Mobile technologies are used widely in many ways to help us with the way we perceive things in our environment. As of now, technologies to recognize facial expressions can now measure the positivity and negativity as well as the intensity of expressed emotions (Gay & Leijdekkers, 2014). This technology can be used to help people with certain conditions that can’t express emotions normally to be able to express their emotions again (Park, Lee, Bertero, Dey, & Fung, 2017; Shen & Barakova, 2017). With this facial recognition technology, we will be able to get inputs from the player’s expressed emotions to enhance player experience by adjusting difficulty based on the player’s expression.
Furthermore, Augmented reality platform can enhance the immersion people experience in experiencing real-world environment while giving feedback in real-time from the virtual world (Roesner, Kohno, & Molnar, 2014). Using this platform, we can improve the player’s immersion while in-game which ultimately lead to the player expressing more emotions for us to use using face expression and emotion recognition.

On the other hand, dynamic balancing is one of the methods that will benefit the player and the developer. The player will be able to enjoy a game as they play it while the developer will be able to leave the constraint of making a static level design (Hunicke, 2005). How will dynamic balancing apply in the endless run game? The endless run game will adjust the difficulty based on the data received with the face expression recognition to reduce or increase it. For example, the amounts of obstacle the player will meet during the run, the speed of the run, and so on.

Using Affdex SDK (McDuff et al., 2016) – the technology used to capture face expression and emotions, and by implementing this SDK into a game in an Augmented Reality environment, we would like to try our hands on how to use these technologies in producing a game by proposing a research about dynamic game balancing in an endless running game on an Augmented Reality platform using face expression recognition technology to detect player expressions while in gameplay. After that, our objective is to record and asses player experience using the questionnaire on Game User Experience Satisfaction (Phan, Keebler, & Chaparro, 2016) as our unit of measurement to determine which of the four groups of environment and conditions give the most satisfying experience. Those four groups are; (1) playing an endless running game without augmented reality platform and face expression and emotion recognition for dynamic balancing, (2) playing an endless running game with augmented reality platform but without face expression and emotion recognition for dynamic balancing, (3) playing an endless running game without augmented reality platform but with face expression and emotion recognition for dynamic balancing, and lastly (4) playing an endless running game with both augmented reality and face expression and emotion recognition for dynamic balancing. Therefore, our hypothesis is that group 4 will have the most satisfying experience.

## Bibliography
Althoff, T., White, R. W., & Horvitz, E. (2016). Influence of Pokémon Go on Physical Activity: Study and Implications. *Journal of Medical Internet Research*, 18(12), e315. https://doi.org/10.2196/jmir.6759

Andrade, G., Ramalho, G., Gomes, A. S., & Corruble, V. (2005). Dynamic Game Balancing: An Evaluation of User Satisfaction. *Proceedings of the Fourth Brazilian Workshop on Computer Games and Digital Entertainment ({WJogos05})*, (January), 66–76.

Blom, P. M., Bakkes, S., Tan, C. T., Whiteson, S., Roijers, D., Valenti, R., & Gevers, T. (2014). Towards personalised gaming via facial expression recognition. *Proceedings of Tenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment.*

Gay, V., & Leijdekkers, P. (2014). Design of emotion-aware mobile apps for autistic children. *Health and Technology*, 4(1), 21–26. https://doi.org/10.1007/s12553-013-0066-3
Hunicke, R. (2005). The case for dynamic difficulty adjustment in games. In *Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology - ACE ’05* (pp. 429–433). New York, New York, USA: ACM Press. https://doi.org/10.1145/1178477.1178573

Lazzaro, N. (2004). Why We Play Games: Four Keys to More Emotion in Player Experiences. *Proceedings of GDC.*

Lopes, A. T., de Aguiar, E., De Souza, A. F., & Oliveira-Santos, T. (2017). Facial expression recognition with Convolutional Neural Networks: Coping with few data and the training sample order. *Pattern Recognition*, 61, 610–628. https://doi.org/10.1016/j.patcog.2016.07.026

McDuff, D., Mahmoud, A., Mavadati, M., Amr, M., Turcot, J., & Kaliouby, R. el. (2016). AFFDEX SDK: A Cross-Platform Real-Time Multi-Face Expression Recognition Toolkit. In *Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’16* (pp. 3723–3726). New York, New York, USA: ACM Press. https://doi.org/10.1145/2851581.2890247

Moniaga, J. V., Chowanda, A., Prima, A., Oscar, & Tri Rizqi, M. D. (2018). Facial Expression Recognition as Dynamic Game Balancing System. *Procedia Computer Science*, 135, 361–368. https://doi.org/10.1016/j.procs.2018.08.185

Park, J. H., Lee, N., Bertero, D., Dey, A., & Fung, P. (2017). Emojive! Collecting emotion data from speech and facial expression using mobile game app. In *Proceedings of the Annual Conference of the International Speech Communication Association*, INTERSPEECH (pp. 827–828). https://doi.org/10.21437/Interspeech.2017-2047

Phan, M. H., Keebler, J. R., & Chaparro, B. S. (2016). The Development and Validation of the Game User Experience Satisfaction Scale (GUESS). *Human Factors: The Journal of the Human Factors and Ergonomics Society*, 58(8), 1217–1247. https://doi.org/10.1177/0018720816669646

Roesner, F., Kohno, T., & Molnar, D. (2014). Security and privacy for augmented reality systems. *Communications of the ACM*, 57(4), 88–96. https://doi.org/10.1145/2580723.2580730
Shen, X., & Barakova, E. I. (2017). My Drama: Story-Based Game for Understanding Emotions in Context. In *Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering*, LNICST (pp. 220–230). https://doi.org/10.1007/978-3-319-49616-0_21

Zaman, B., & Shrimpton-Smith, T. (2006). The FaceReader: Measuring Instant Fun of Use. *Proceedings of the 4th Nordic Conference on Human-Computer Interaction Changing Roles - NordiCHI ’06*, 457–460. https://doi.org/10.1145/1182475.1182536